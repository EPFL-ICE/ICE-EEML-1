{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acbed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from numpy import set_printoptions\n",
    "import plotly.graph_objects as go\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa7553",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76493c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FROM COSMED\n",
    "os.chdir(r\"COSMED_FILEPATH\")\n",
    "\n",
    "ee = pd.read_excel(\"cosmed_filename.xlsx\", usecols=[3,4,9,10,13,14,61,65,67,69,73], names=[\"label\",\"data\",\"time\",\"RR\",\"VO2\",\"VCO2\",\"TDEE\",\"PRO\",\"FAT\",\"CHO\",\"npRQ\"])\n",
    "\n",
    "date = ee[\"data\"][0]\n",
    "time = \"08:27:32\"\n",
    "date_time_str = date+\" \"+time\n",
    "ee.drop([0, 1], inplace=True)\n",
    "ee.drop(columns=['label', 'data'], inplace=True)\n",
    "start_time = datetime.strptime(date_time_str, '%d/%m/%Y %H:%M:%S')\n",
    "ee[\"timestep\"] = 0\n",
    "for i in ee.index:\n",
    "    ee[\"timestep\"][i] =  start_time + timedelta(hours=int(ee[\"time\"][i][:2]), minutes=int(ee[\"time\"][i][3:5]), seconds=int(ee[\"time\"][i][6:]))\n",
    "\n",
    "ee.drop(columns=['time'], inplace=True)\n",
    "ee['timestep'] = pd.to_datetime(ee['timestep'],format=\"%Y/%m/%d %H:%M:%S\")\n",
    "ee['TDEE_avg'] = ee['TDEE'].rolling(15).mean()\n",
    "ee = ee.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "#DATA FROM ENVIRONMENTAL MEASUREMENTS\n",
    "os.chdir(r\"ENV_filepath\")\n",
    "\n",
    "a3 = pd.read_csv(\"A3.csv\", skiprows=2, usecols=[1,2,3,4,5], names=[\"timestep\",\"Tair_a3\",\"Tgl_a3\",\"Vair_a3\",\"Tair,v_a3\"])\n",
    "a3['timestep'] = pd.to_datetime(a3['timestep'])\n",
    "a3 = a3.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "b3 = pd.read_csv(\"B3.csv\", skiprows=2, usecols=[1,2,3,4,5], names=[\"timestep\",\"Tair_b3\",\"Tgl_b3\",\"Vair_b3\",\"Tair,v_b3\"])\n",
    "b3['timestep'] = pd.to_datetime(b3['timestep'])\n",
    "b3 = b3.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "\n",
    "#DATA FROM CORE\n",
    "os.chdir(r\"CORE_FILEPATH\")\n",
    "\n",
    "core = pd.read_excel(\"CORE_filename.xlsx\", usecols=[0,7,8,9,12], names=[\"timestep\",\"ACCx_lchest\",\"ACCy_lchest\",\"ACCz_lchest\",\"Tcore_lchest\"], skiprows=14)\n",
    "core['timestep'] = pd.to_datetime(core['timestep'])\n",
    "core[\"ACCmag_lchest\"] = np.sqrt(core[\"ACCx_lchest\"]**2 + core[\"ACCy_lchest\"]**2 + core[\"ACCz_lchest\"]**2)\n",
    "core['timestep'] = core['timestep'].dt.floor('s')   \n",
    "core = core.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "#DATA FROM gSKIN\n",
    "os.chdir(r\"gSKIN_FILEPATH\")\n",
    "\n",
    "gskin_chest = pd.read_excel(\"gSKIN_chest_filename.xlsx\", usecols=[0,7,8,9,13,14], names=[\"timestep\",\"ACCx_uchest\",\"ACCy_uchest\",\"ACCz_uchest\",\"HFa_uchest\",\"HFb_uchest\"], skiprows=14) \n",
    "gskin_chest['timestep'] = pd.to_datetime(gskin_chest['timestep'])\n",
    "gskin_chest[\"ACCmag_uchest\"] = np.sqrt(gskin_chest[\"ACCx_uchest\"]**2 + gskin_chest[\"ACCy_uchest\"]**2 + gskin_chest[\"ACCz_uchest\"]**2)\n",
    "gskin_chest['timestep'] = gskin_chest['timestep'].dt.floor('s')   \n",
    "gskin_chest = gskin_chest.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "\n",
    "gskin_hand = pd.read_excel(\"gSKIN_hand_filename.xlsx\", usecols=[0,7,8,9,12,13], names=[\"timestep\",\"ACCx_hand\",\"ACCy_hand\",\"ACCz_hand\",\"HFa_hand\",\"HFb_hand\"], skiprows=14) \n",
    "gskin_hand['timestep'] = pd.to_datetime(gskin_hand['timestep'])\n",
    "gskin_hand[\"ACCmag_hand\"] = np.sqrt(gskin_hand[\"ACCx_hand\"]**2 + gskin_hand[\"ACCy_hand\"]**2 + gskin_hand[\"ACCz_hand\"]**2)\n",
    "gskin_hand['timestep'] = gskin_hand['timestep'].dt.floor('s')\n",
    "gskin_hand = gskin_hand.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "#DATA FROM EMPATICA E4\n",
    "os.chdir(r\"Empatica_filepath\")\n",
    "\n",
    "#The first row is the initial time of the session expressed as unix timestamp in UTC.The second row is the sample rate expressed in Hz.\n",
    "\n",
    "#Data from 3-axis accelerometer sensor. The accelerometer is configured to measure acceleration in the range [-2g, 2g]. Therefore the unit in this file is 1/64g. Data from x, y, and z axis are \n",
    "#respectively in first, second, and third column.\n",
    "acc = pd.read_csv(\"ACC.csv\", usecols=[0,1,2], names=[\"ACCx_wrist\",\"ACCy_wrist\",\"ACCz_wrist\"])\n",
    "#Data from photoplethysmograph\n",
    "bvp = pd.read_csv(\"BVP.csv\", usecols=[0], names=[\"BVP_wrist\"])\n",
    "#Data from the electrodermal activity sensor expressed as microsiemens (μS).\n",
    "eda = pd.read_csv(\"EDA.csv\", usecols=[0], names=[\"EDA_wrist\"])\n",
    "#Average heart rate extracted from the BVP signal.The first row is the initial time of the session expressed as unix timestamp in UTC.The second row is the sample rate expressed in Hz.\n",
    "hr = pd.read_csv(\"HR.csv\", usecols=[0], names=[\"HR_wrist\"])\n",
    "#Data from temperature sensor expressed degrees on the Celsius (°C) scale.\n",
    "t_skin = pd.read_csv(\"TEMP.csv\", usecols=[0], names=[\"Tskin_wrist\"])\n",
    "\n",
    "start_time, freq = 0, 0\n",
    "\n",
    "#Processing the timesteps for the accelerometer data and calculating the vector magnitudes (32 hz)\n",
    "start_time = datetime.utcfromtimestamp(acc[\"ACCx_wrist\"][0]).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "freq = acc[\"ACCx_wrist\"][1]\n",
    "acc.drop([0, 1], inplace=True)\n",
    "acc[\"timestep\"] = pd.date_range(start_time, periods=acc.shape[0], freq=str(1000000/freq)+'U')\n",
    "acc[\"ACCmag_wrist\"] = np.sqrt(acc[\"ACCx_wrist\"]**2 + acc[\"ACCy_wrist\"]**2 + acc[\"ACCz_wrist\"]**2)\n",
    "acc = acc.sort_values(by='timestep', ascending=True)\n",
    "acc = acc.set_index('timestep').resample('S').mean()\n",
    "\n",
    "#Processing the timesteps for the bvp (64 hz)\n",
    "start_time = datetime.utcfromtimestamp(bvp[\"BVP_wrist\"][0]).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "freq = bvp[\"BVP_wrist\"][1]\n",
    "bvp.drop([0, 1], inplace=True)\n",
    "bvp[\"timestep\"] = pd.date_range(start_time, periods=bvp.shape[0], freq=str(1000000/freq)+'U')\n",
    "bvp = bvp.sort_values(by='timestep', ascending=True)\n",
    "bvp = bvp.set_index('timestep').resample('S').mean()\n",
    "\n",
    "#Processing the timesteps for the eda (4 hz)\n",
    "start_time = datetime.utcfromtimestamp(eda[\"EDA_wrist\"][0]).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "freq = eda[\"EDA_wrist\"][1]\n",
    "eda.drop([0, 1], inplace=True)\n",
    "eda[\"timestep\"] = pd.date_range(start_time, periods=eda.shape[0], freq=str(1000000/freq)+'U')\n",
    "eda = eda.sort_values(by='timestep', ascending=True)\n",
    "eda = eda.set_index('timestep').resample('S').mean()\n",
    "\n",
    "#Processing the timesteps for the hr (1 hz)\n",
    "start_time = datetime.utcfromtimestamp(hr[\"HR_wrist\"][0]).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "freq = hr[\"HR_wrist\"][1]\n",
    "hr.drop([0, 1], inplace=True)\n",
    "hr[\"timestep\"] = pd.date_range(start_time, periods=hr.shape[0], freq=str(1000000/freq)+'U')\n",
    "hr = hr.sort_values(by='timestep', ascending=True)\n",
    "hr = hr.set_index('timestep').resample('S').mean()\n",
    "\n",
    "#Processing the timesteps for the t_wrist (1 hz)\n",
    "start_time = datetime.utcfromtimestamp(t_skin[\"Tskin_wrist\"][0]).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "freq = t_skin[\"Tskin_wrist\"][1]\n",
    "t_skin.drop([0, 1], inplace=True)\n",
    "t_skin[\"timestep\"] = pd.date_range(start_time, periods=t_skin.shape[0], freq=str(1000000/freq)+'U')\n",
    "t_skin = t_skin.sort_values(by='timestep', ascending=True)\n",
    "t_skin = t_skin.set_index('timestep').resample('S').mean()\n",
    "\n",
    "#Processing the data from MOX --> NOT the good data \n",
    "os.chdir(r\"MOX_filepath\")\n",
    "mox = pd.read_csv(\"filename.csv\", usecols=[0,1,2,3], names=[\"timestep\",\"ACCx_thigh\",\"ACCy_thigh\",\"ACCz_thigh\"], skiprows=1)\n",
    "mox['timestep'] = pd.to_datetime(mox['timestep'], format='%d-%m-%Y %H:%M:%S')\n",
    "mox[\"ACCmag_thigh\"] = np.sqrt(mox[\"ACCx_thigh\"]**2 + mox[\"ACCy_thigh\"]**2 + mox[\"ACCz_thigh\"]**2)\n",
    "mox = mox.sort_values(by='timestep', ascending=True)\n",
    "mox = mox.set_index('timestep').resample('S').mean()\n",
    "\n",
    "#Processing the data from Actiheart\n",
    "os.chdir(r\"Actiheart_filepath\")\n",
    "acti = pd.read_excel(\"Actiheart_filename.xlsx\", usecols=[4], names=[\"BPM_chest\"], skiprows=14)\n",
    "start_time = datetime.strptime('YYYY-MM-DD HH:MM:SS', '%Y-%m-%d %H:%M:%S')\n",
    "acti[\"timestep\"] = pd.date_range(start_time, periods=acti.shape[0], freq='30S')\n",
    "\n",
    "#Processing the data from Ibuttons\n",
    "os.chdir(r\"IButtons_filepath\")\n",
    "ib = pd.read_excel(\"iButtons_filename.xlsx\", usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24], skiprows=1, sheet_name='Raw Data',\n",
    "                   names=[\"Tskin_forehead\",\"Tskin_neck\",\"Tskin_rscapula\",\"Tskin_luchest\",\"Tskin_ruarm\",\"Tskin_luarm\",\"Tskin_rlarm\",\"Tskin_llarm\",\"Tskin_lhand\",\"Tskin_rabdomen\",\"Tskin_rpvbl\",\"Tskin_lpvbl\",\"Tskin_rathigh\",\"Tskin_lathigh\",\n",
    "                          \"Tskin_rpthigh\",\"Tskin_lpthigh\",\"Tskin_rshin\",\"Tskin_lshin\",\"Tskin_rcalf\",\"Tskin_lcalf\",\"Tskin_rinstep\",\"Tskin_linstep\",\"Tskin_rfinger\",\"Tskin_lfinger\"])\n",
    "\n",
    "\n",
    "#Processing the timesteps for the ibuttons (0.1 hz)\n",
    "start_time = datetime.strptime('YYYY-MM-DD HH:MM:SS', '%Y-%m-%d %H:%M:%S')\n",
    "ib[\"timestep\"] = pd.date_range(start_time, periods=ib.shape[0], freq=str(10)+'S')\n",
    "ib = ib.sort_values(by='timestep', ascending=True)\n",
    "\n",
    "#merge all data\n",
    "e4_data = pd.merge_asof(ee, eda, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, acc, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, hr, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, t_skin, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, bvp, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, mox, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, ib, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, core, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, acti, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, gskin_chest, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, gskin_hand, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, a3, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = pd.merge_asof(e4_data, b3, on = 'timestep', tolerance=pd.Timedelta('5s'))\n",
    "e4_data = e4_data.ffill(axis = 0)\n",
    "e4_data.dropna(inplace=True)\n",
    "\n",
    "#drop lchest values \n",
    "e4_data = e4_data.drop(columns = ['ACCx_lchest', 'ACCy_lchest', 'ACCz_lchest','ACCmag_lchest'])\n",
    "e4_data.reset_index(inplace=True)\n",
    "\n",
    "#clean outliers in npRQ\n",
    "def find_indices(list_to_check):\n",
    "    return [idx for idx, value in enumerate(list_to_check) if value < 0.6 or value > 1.2]\n",
    "\n",
    "idx_data = find_indices(e4_data.npRQ)\n",
    "e4_data.loc[idx_data,'TDEE'] = np.nan\n",
    "e4_data.TDEE = e4_data.TDEE.fillna(method = 'ffill')\n",
    "\n",
    "#apply rolling mean on EE signal\n",
    "e4_data.TDEE_avg = e4_data.TDEE.rolling(15).mean()\n",
    "\n",
    "\n",
    "#Save the clean file \n",
    "e4_data.to_excel(r'filename.xlsx', index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa2320",
   "metadata": {},
   "source": [
    "### Generating correlation matrix\n",
    "A correlation matrix is a table showing correlation coefficients between sets of variables. Each random variable (Xi) in the table is correlated with each of the other values in the table (Xj). This allows you to see which pairs have the highest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b633da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('filename.xlsx')\n",
    "\n",
    "corr = data.corr(method='pearson', min_periods=1)\n",
    "fig_corr = px.imshow(corr, width=1800, height=1200, template=\"simple_white\")\n",
    "fig_corr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc3257",
   "metadata": {},
   "source": [
    "### Percentage correlation explained by the variables\n",
    "Often, you might be interested in seeing how much variance PCA is able to explain as you increase the number of components, in order to decide how many dimensions to ultimately keep or analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['timestep','TDEE','TDEE_avg'])\n",
    "y = data[[\"TDEE_avg\"]]\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_std = sc.transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_std)\n",
    "exp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "fig_var = px.area(x=range(1, exp_var_cumul.shape[0] + 1),y=exp_var_cumul,labels={\"x\": \"No. of Components\", \"y\": \"Explained Variance (-)\"}, template=\"simple_white\")\n",
    "fig_var.update_xaxes(range=[0, 30])\n",
    "fig_var.update_layout(width=900, height=600)\n",
    "fig_var.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460f3f8",
   "metadata": {},
   "source": [
    "### Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable. The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed21491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SelectKBest class to extract top 10 best features\n",
    "X = data.drop(columns=['timestep','TDEE','TDEE_avg']).values\n",
    "y = data[\"TDEE_avg\"].values\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=f_regression, k=20)\n",
    "fit = test.fit(X, y)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "scores = fit.scores_\n",
    "print(scores)\n",
    "\n",
    "feat_fig = go.Figure(go.Bar(x=scores, y=data.drop(columns=['timestep','TDEE','TDEE_avg']).columns, orientation='h'))\n",
    "feat_fig.update_layout(width=900, height=1200, template=\"simple_white\", xaxis_title=\"F-value between features and EE (-)\")\n",
    "feat_fig.show()\n",
    "\n",
    "# Reduce the features to the best 20\n",
    "features = fit.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
