{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9a27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from numpy import set_printoptions\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgbm\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3c4be",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a65d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "os.chdir(r\"filepath\")\n",
    "dataset = pd.read_excel('filename.xlsx')\n",
    "\n",
    "#data split\n",
    "dataset_train = dataset[:int(0.75*len(dataset))]\n",
    "dataset_test = dataset[int(0.75*len(dataset)):]\n",
    "\n",
    "#training data\n",
    "X_train = dataset_train[['BPM_chest','ACCx_thigh','ACCmag_uchest','ACCx_uchest','ACCz_thigh', 'ACCy_thigh','Tskin_lpthigh',\n",
    "                  'Tskin_rpthigh','Tskin_rshin','ACCy_uchest']]\n",
    "y_train = dataset_train[[\"TDEE_avg\"]]\n",
    "import re\n",
    "X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "#test data\n",
    "\n",
    "real_tdee = dataset_test[[\"TDEE_avg\"]]\n",
    "X_test = dataset_test[['BPM_chest','ACCx_thigh','ACCmag_uchest','ACCx_uchest','ACCz_thigh', 'ACCy_thigh','Tskin_lpthigh',\n",
    "                  'Tskin_rpthigh','Tskin_rshin','ACCy_uchest']]\n",
    "X_test = X_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3892db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of the tuning space\n",
    "\n",
    "space= {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "    \n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = space\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_absolute_error(y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09127a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=lgbm.LGBMRegressor(**space)\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, real_tdee)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,eval_set=evaluation,\n",
    "                **xgb_para['fit_params'])\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    mae = mean_absolute_error(real_tdee/1400, pred/1400)\n",
    "    mape = mean_absolute_percentage_error(real_tdee/1400, pred/1400)\n",
    "    print (\"SCORE:\", mape)\n",
    "    return {'loss': mae, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eed612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use best hyperparameters found with tuning to train the model\n",
    "\n",
    "clf=lgbm.LGBMRegressor(colsample_bytree = 0.3, learning_rate=0.05, max_depth = 5, min_child_weight = 1, subsample = 0.8,\n",
    "                    n_estimators = 100)\n",
    "    \n",
    "    \n",
    "evaluation = [( X_train, y_train), ( X_test, real_tdee)]\n",
    "clf.fit(X_train, y_train, eval_set=evaluation,\n",
    "                **xgb_para['fit_params'])\n",
    "    \n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "### COMPUTE METRICS ERROR FOR LGBM ###\n",
    "print('R2:',r2_score(real_tdee/1400, pred/1400))\n",
    "print('MAE:',mean_absolute_error(real_tdee/1400, pred/1400))\n",
    "print('MAPE: ', mean_absolute_percentage_error(real_tdee/1400, pred/1400))\n",
    "print('MSE:',mean_squared_error(real_tdee/1400, pred/1400, squared=True))\n",
    "print('RMSE:',mean_squared_error(real_tdee/1400, pred/1400, squared=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3954cfa",
   "metadata": {},
   "source": [
    "### Aggregate LGBM predicitions with CNN-LSTM predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"filepath\")\n",
    "data_convLSTM = pd.read_excel('filename_results_CNNLSTM.xlsx')\n",
    "pred_convLstm = data_convLSTM.predicted_TDEE\n",
    "\n",
    "#computation of the mean\n",
    "data = np.array([pred_convLstm, pred/1400])\n",
    "mean_signal = np.mean(data, axis = 0)\n",
    "\n",
    "#Print the error metrics of the LSTM-LGBM model\n",
    "print('R2:',r2_score(real_tdee/1400, mean_signal))\n",
    "print('MAE:',mean_absolute_error(real_tdee/1400, mean_signal))\n",
    "print('MAPE: ', mean_absolute_percentage_error(real_tdee/1400, mean_signal))\n",
    "print('MSE:',mean_squared_error(real_tdee/1400, mean_signal, squared=True))\n",
    "print('RMSE:',mean_squared_error(real_tdee/1400, mean_signal, squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save predictions in a xlsx file\n",
    "df = pd.DataFrame({'Real_TDEE':real_tdee.values.flatten()/1400,'Mean_signal':mean_signal,'Signal_LGBM':pred/1400,'Signal_LSTM':pred_convLstm.values})\n",
    "\n",
    "df.to_excel(r'filename.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-venv",
   "language": "python",
   "name": "tf-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
